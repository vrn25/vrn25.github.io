<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Videh Raj Nema</title>

    <meta name="author" content="Videh Raj Nema">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Videh Raj Nema
                </p>
                <p>
		I am a PhD student advised by <a href="https://dsai.iitm.ac.in/~ravi/">Prof. Balaraman Ravindran</a> at the <a href="https://wsai.iitm.ac.in">Wadhwani School of Data Science & AI</a>, <a href="https://www.iitm.ac.in">Indian Institute of Technology, Madras</a>. My research focuses on building an Ātmanirbhara Bhārata in STEM (a self-reliant and strong India). Presently, I work on multimodal machine learning for information synthesis. Further, my research methodology focuses on building intelligent autonomous agents that are compatible (and not necessarily indistinguishable) with humans and other intelligent agencies in a wide range of dynamic environments. Previously, I was a thesis-based MS student at the <a href="https://www.ualberta.ca/en/index.html">University of Alberta</a>. I was advised by <a href="https://drmatttaylor.net">Prof. Matthew Taylor</a> at the <a href="https://irll.ca">Intelligent Robot Learning lab</a>, where I worked on reinforcement learning with multiple learning agents and humans integrated in a learning loop. I received the UAlberta graduate research fellowship. I completed my undergraduate in computer science and engineering from the <a href="https://www.nitk.ac.in">National Institute of Technology Karnataka, Surathkal</a>. During undergrad, I did research on reinforcement learning and received the <a href="https://sfp.caltech.edu/undergraduate-research/programs/surf">SURF</a> fellowship from <a href="https://www.caltech.edu">Caltech</a>.</p>
        
        <p>
        My research is driven towards achieving the goals of the National vision of Vikasita Bhārata@2047 and the "remaking of Bhārata". AI is a crucial technology and we need to build AI for Bhārata and build Bhārata stronger with AI in a way that is grounded in the Indian culture/values (Bhāratīyatā) and tailored to meet Bhārata's needs and interests. Concurrently, I am also interested in <a href="https://iksindia.org">Indian Knowledge Systems</a> (Bhāratīya Jñāna Paramparā) towards the effort of bringing in the "Bhāratīya" way of thought, speech, and action in STEM along with restoring the lost Indian knowledge and applying it in the present context.
                </p>
                <p style="text-align:center">
                  <a href="mailto:videhrn25@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/VidehRajNemaCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=5_oWlJAAAAAJ&hl=en">G-Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/vrn25/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vrn25">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/Videh.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Videh.png" class="hoverZoomLink"></a>
                <img style="width:100%;max-width:100%;margin-top:20px;" alt="quote" src="images/dharma.png">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                My research has mainly been on reinforcement learning. Lately, I have been working on multimodal machine learning and omni-modal LLMs.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="ms_thesis_stop()" onmouseover="ms_thesis_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ms_thesis_image'>
        <img src='images/ms_thesis_after.png' width=100%>
      </div>
      <img src='images/ms_thesis_before.png' width=100%>
    </div>
    <script type="text/javascript">
      function ms_thesis_start() {
        document.getElementById('ms_thesis_image').style.opacity = "1";
      }

      function ms_thesis_stop() {
        document.getElementById('ms_thesis_image').style.opacity = "0";
      }
      ms_thesis_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <!-- <a href="https://ualberta.scholaris.ca/items/bdfa3c85-9990-406d-8e33-fc43562f05cf/full"> -->
      <span class="papertitle">Continual Preference-based Reinforcement Learning with Hypernetworks</span>
    <!-- </a> -->
    <br>
    <strong>Videh Raj Nema</strong>
    <br>
    <em>University of Alberta</em>, Spring 2025
    <br>
    <a href="https://ualberta.scholaris.ca/items/bdfa3c85-9990-406d-8e33-fc43562f05cf/full">Thesis page</a>
    <em>Nominated for the UAlberta Computing Science MS Outstanding Thesis Award</em>
    <p></p>
    <p>
	Master's thesis on continual reward learning based on non-stationary teacher preferences using regularized hypernetworks. This takes a step toward human-agent interaction for the real world where the interaction is continual and the human's preferences are non-stationary.
    </p>
  </td>
</tr>

<tr onmouseout="increasing_replay_stop()" onmouseover="increasing_replay_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='increasing_replay_image'>
        <img src='images/increasing_replay_after.png' width=100%>
      </div>
      <img src='images/increasing_replay_before.png' width=100%>
    </div>
    <script type="text/javascript">
      function increasing_replay_start() {
        document.getElementById('increasing_replay_image').style.opacity = "1";
      }

      function increasing_replay_stop() {
        document.getElementById('increasing_replay_image').style.opacity = "0";
      }
      increasing_replay_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <!-- <a href=""> -->
      <span class="papertitle">Understanding the effect of varying amounts of replay per step</span>
    <!-- </a> -->
    <br>
    <a href="https://ca.linkedin.com/in/animesh-kumar-paul">Animesh Kumar Paul</a>,
    <strong>Videh Raj Nema</strong>
    (equal contribution; work done as a part of the RL-1 course taught by <a href="https://sites.ualberta.ca/~amw8/">Prof. Adam White</a> at the University of Alberta)
    <br>
    <em>arXiv</em>, 2023
    <br>
    <a href="https://arxiv.org/pdf/2302.10311">arXiv</a>
    <p></p>
    <p>
	A systematic study on the effect of varying amounts of replay per step in Deep Q-Networks (DQN). Strong empirical evidence that increasing replay improves DQN's sample efficiency, reduces the variation in its performance, and makes it more robust to change in hyperparameters.
    </p>
  </td>
</tr>

<tr onmouseout="ipo_stop()" onmouseover="ipo_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ipo_image'>
        <img src='images/ipo_after.png' width=100%>
      </div>
      <img src='images/ipo_before.png' width=100%>
    </div>
    <script type="text/javascript">
      function ipo_start() {
        document.getElementById('ipo_image').style.opacity = "1";
      }

      function ipo_stop() {
        document.getElementById('ipo_image').style.opacity = "0";
      }
      ipo_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <!-- <a href=""> -->
      <span class="papertitle">Interactive Robust Policy Optimization for Multi-Agent Reinforcement Learning</span>
    <!-- </a> -->
    <br>
    <strong>Videh Raj Nema</strong>,
    <a href="https://dsai.iitm.ac.in/~ravi/">Balaraman Ravindran</a>
    <br>
    <em>NeurIPS <a href="https://sites.google.com/view/deep-rl-workshop-neurips2021">Deep RL</a> and <a href="https://www.strategic-ml.com">Strategic-ML workshops</a></em>, 2021
    <br>
    <a href="https://drive.google.com/file/d/1trE04xRLcBVidU_0ZDfVihJUfqLE4b4c/view?usp=sharing">Paper</a>
    <p></p>
    <p>
	Addressing non-stationarity and robustness in multi-agent reinforcement learning using principles from game theoretical optimization and adversarial learning, respectively. This work provides practical policy gradient (stochastic and deterministic), natural policy gradient, and trust-region algorithms for multi-agent reinforcement learning using centralized training and decentralized execution.
    </p>
  </td>
</tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <p>
                For more research projects and internships, academics, and extra-curricular, please refer to the <a href="data/VidehRajNemaCV.pdf">CV</a>.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://jonbarron.info">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>