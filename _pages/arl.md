---
permalink: /projects/arl/
title: "Adversarial Reinforcement Learning"
author_profile: true
---

This was a project under the [IEEE NITK](https://github.com/IEEE-NITK) Computer Society. The objective of this project was to explore adversarial attacks and defenses in single as well as multi-agent systems. In the single-agent domains, we focus on pixel-based attacks to explore the vulnerabilites in current function approximators (like neural networks) used with popular deep reinforcement learning algorithms (like PPO, DQN, etc) taking pixel-input in [atari](https://gym.openai.com/envs/#atari) games from the [Gym](https://gym.openai.com/) environments. In multi-agent, we concentrate on attacking SOTA self-play policies by training adversarial policies, that take actions that are naturally adversarial to the other agent, in 1-vs-1 zero-sum continuous control robotic environments from the [MuJoCo](http://www.mujoco.org/) simulator. We also studied potential defense procedures to counter such attacks.

More details about the work done during the project can be found [here](https://github.com/IEEE-NITK/Adversarial-Reinforcement-Learning/blob/master/README.md).

A detailed article about the methods and approaches studied during the project can be found [here](https://aarl-ieee-nitk.github.io/reinforcement-learning,/adversarial/attacks,/defense/mechanisms/2020/04/09/Survey-on-Adversarial-attacks-and-defenses.html). We have also implemented some of these in this [repository](https://github.com/IEEE-NITK/Adversarial-Reinforcement-Learning).

Following are some other links:

[Code](https://github.com/IEEE-NITK/Adversarial-Reinforcement-Learning) | [Video](https://www.youtube.com/watch?v=j1Img72wp00) | [Slides](https://docs.google.com/presentation/d/1abcZFKxxbL9te_5kJRXvm1dOb9KnxtQOSaLdDFJwqFw/edit?usp=sharing) | [Blog](https://aarl-ieee-nitk.github.io/) | [Org](https://github.com/aarl-ieee-nitk) | [Expo](https://ieee.nitk.ac.in/virtual-expo/adversarial-reinforcement-learning/)